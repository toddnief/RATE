{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Using the OpenAI Batch API (for rewrites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful links:\n",
    "- Pricing of available models: https://openai.com/api/pricing/\n",
    "    - This seems to be the only way to find the lastest, cheaper version of GPT 4o, which is half the price of the default GPT-4o (as of 8/30/24)\n",
    "\n",
    "- official docs for the Batch API: https://platform.openai.com/docs/guides/batch/getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load imdb for examples\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Batch API related imports\n",
    "from openai import OpenAI # OpenAI API\n",
    "import json # for creating batch files\n",
    "\n",
    "# And for loading the API key from the .env file\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the data you want to send to Chat-GPT\n",
    "\n",
    "We'll just consider the task of rewriting the length of some IMDB reviews. So, we'll load the reviews like normal (and add a feature about whether it's long or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load imdb dataset from huggingface\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "# create pandas dataframe with both label and text, including both train and test data\n",
    "imdb = pd.DataFrame({'text': dataset['train']['text'] + dataset['test']['text'], 'label': dataset['train']['label'] + dataset['test']['label']})\n",
    "\n",
    "# Remove samples which have length greater than 4000 characters\n",
    "imdb = imdb[imdb['text'].apply(lambda x: len(x) < 4000)]\n",
    "\n",
    "# Bin text lengths\n",
    "imdb.loc[:, 'text_length'] = imdb['text'].str.len()\n",
    "length_threshold = 1200\n",
    "imdb['is_long'] = imdb['text_length'] > length_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way that the batch API works is by sending all your requests at once in a jsonl file.\n",
    "\n",
    "So, we'll write a few functions which define the rewriting task, then save those to a jsonl file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example input:\n",
    "\n",
    "{\"custom_id\": \"9546\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o\", \"messages\": [{\"role\": \"user\", \"content\": \"This is a movie review...\"}], \"temperature\": 0.7}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt that we will use to generate rewrites\n",
    "def review_messages(review, is_long):\n",
    "    \"\"\"\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello world!\"}]\"\"\"\n",
    "\n",
    "    flipped_length = \"longer\" if is_long == 0 else \"shorter\"\n",
    "    counterfactual_prompt = f\"\"\"\n",
    "    Original Completion: \n",
    "    {review}\n",
    "    [Adjust the original completion so it's 50% {flipped_length}, but change *nothing* else.]\n",
    "    Adjusted Completion:\n",
    "    \"\"\"\n",
    "    \n",
    "    messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": counterfactual_prompt,\n",
    "                },\n",
    "            ]\n",
    "    return messages\n",
    "\n",
    "# create each line of the batch input file\n",
    "def write_input_jsonl(df, batch_input_filename):\n",
    "    batch_input = []\n",
    "    for idx, row in df.iterrows():\n",
    "        messages = review_messages(row['text'], row['label'])\n",
    "        batch_input.append({\n",
    "            \"custom_id\": str(idx), # Each request needs a unique ID! Will fail otherwise\n",
    "            \"method\": \"POST\", # only option for now\n",
    "            \"url\": \"/v1/chat/completions\", # endpoint for chat completions\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o-2024-08-06\", # This is the cheapest model (as of 8/30/24). It may not be the highest quality.\n",
    "                \"messages\": messages,\n",
    "                \"temperature\": 0.7\n",
    "            }\n",
    "        })\n",
    "    # save the batch input file as jsonl\n",
    "    with open(batch_input_filename, 'w') as f:\n",
    "        for item in batch_input:\n",
    "            json.dump(item, f)  # Properly escape quotes and special characters\n",
    "            f.write(\"\\n\")  # Ensure each JSON object is on a new line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the batch input file\n",
    "batch_input_filename = \"batch_api_data/sentiment_batch_input.jsonl\"\n",
    "\n",
    "# only sample 10 examples for now, for illustration purposes\n",
    "write_input_jsonl(imdb.sample(10), batch_input_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rewrites from OpenAI Batch API\n",
    "\n",
    "Now that we have our batch file created, we're ready to submit our batch!\n",
    "\n",
    "First, we setup the OpenAI client like normal. Then, we upload our batch file, and start the batch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the OpenAI client\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_SNvLgDYvpYOuRkOphpRygNjV', completion_window='24h', created_at=1725053789, endpoint='/v1/chat/completions', input_file_id='file-4HYg6vMt0iN9Zo9jCsg5BbBQ', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1725140189, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'length rewrite'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "# Upload the batch file\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(batch_input_filename, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "# Create the batch job\n",
    "batch = client.batches.create(\n",
    "    input_file_id=batch_input_file.id, # the file we just uploaded\n",
    "    endpoint=\"/v1/chat/completions\", # this is the default (only?) endpoint\n",
    "    completion_window=\"24h\", # this is the only option\n",
    "    metadata={\n",
    "        \"description\":\"length rewrite\" # Pick a descriptive name\n",
    "    }\n",
    ")\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check on the status of the batch using the following command. Once status='completed', you're ready to download it! (usually only a couple minutes, if that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_SNvLgDYvpYOuRkOphpRygNjV', completion_window='24h', created_at=1725053789, endpoint='/v1/chat/completions', input_file_id='file-4HYg6vMt0iN9Zo9jCsg5BbBQ', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1725053797, error_file_id=None, errors=None, expired_at=None, expires_at=1725140189, failed_at=None, finalizing_at=1725053797, in_progress_at=1725053789, metadata={'description': 'length rewrite'}, output_file_id='file-PHCHnuVftEDXrqK0BbRkTQ31', request_counts=BatchRequestCounts(completed=10, failed=0, total=10))\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and print the details of the batch\n",
    "print(client.batches.retrieve(batch.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the batch output file\n",
    "batch_output_filename = \"batch_api_data/sentiment_batch_output.jsonl\"\n",
    "\n",
    "# Retrieve the output file and write it to a local file\n",
    "content = client.files.content(client.batches.retrieve(batch.id).output_file_id)\n",
    "content.write_to_file(batch_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the outputs\n",
    "\n",
    "The main thing to note is that the outputs may be out of order (which is why we assigned unique IDs). \n",
    "\n",
    "You can also see any error messages, if any."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
